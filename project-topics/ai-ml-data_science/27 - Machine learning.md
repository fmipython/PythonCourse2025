# Тема за проект 27 -  Machine Learning

## Описание

Всички от изброените теми изискват използването на machine learning модели за класификация. Целта е на база наличните данни да се предвиди класа (категорията), към който принадлежи нов, непознат пример.

За реализирането на всяка тема се изисква подходящ набор от данни (dataset). Можете да потърсите и използвате публично достъпни такива (например от [Kaggle](https://www.kaggle.com/datasets), [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php) или др.), или да съберете свои собствени (например чрез уеб скрейпинг, анкети и др.). Пишете ни, ако не намирите нищо подходящо.

## Варианти

### A. Предсказване на възраст/пол/настроение по снимка

### B. Сегментиране на потребители/клиенти

### C. Откриване на аномалии/измами

### D. Засичане на природни бедствия (наводнения, пожари, нефтени разливи или др.) по сателитни снимки

### E. Класифициране на ревюта (на хотели, книги, филми или др.) или коментари/постове в соц. мрежи

### F. Откриване на медицински заболявания (напр. рак, тумори, паркинсон или др.)

### G. E-Mail spam detector
### H. Генериране на описания на изображения (image captions)

## Задължителни основни изисквания

- Избор и подготовка на подходящ набор от данни (dataset).
- Избор на готов machine learning модел, който може да се използва за класификация в дадения контекст.
  - Може да намерите и свалите предварително обучен (pre-trained) модел, специално създаден за решаване на конкретната задача. [Hugging Face](https://huggingface.co/models) е добра отправна точка.
  - Алтернативно, за задачи с данни в свободен текст и/или снимки, може просто да използвате наготово претренирани големи модели с по-обща насоченост, като например LLM-и (Large Language Models). Има и такива с отворен достъп, но поради големите ресурси, които се изискват за локалното им пускане, препоръчваме директно извикване на модели чрез съответните им API-та (като тези на OpenAI, Anthropic, Google Vertex, DeepSeek, Qwen и др.). (Повечето са платени, но не вярваме повече от един-два долара да изразходите за целите на всички задачи. Все пак внимавайте с броя данни и сметнете очаквания разход по токени преди да пуснете някой платен модел по целия набор от данни.)
- Избор на подходящи метрики за оценка на модела.
- Имплементация на процес за оценка на модела върху тестовите данни, като се използват избраните метрики. Визуализация на резултатите с подходящи графики.
- Кратка демо апликация, която позволява на потребителя да получи предсказание от модела и да го изпробва.

## Задължителен избор от следните допълнителни изисквания (изберете 1):

### Вариация А

- Трениране на собствен модел.
  - Избор и имплементация на подходящ вид модел - напр. дървета, SVM, невронни мрежи (напр. feedforward, CNN, RNN, трансформъри). т.н. За тема 3 (аномалии) е възможен и unsupervised подход. Възможен е и хибриден подход - например фино настройване (fine-tuning) на предварително обучен трансформър модел.
  - Разделяне на данните на тренировъчни и тестови (евентуално и валидационни).
  - Трениране на модела върху тренировъчните данни с оценка върху валидационните чрез подходяща loss функция.
  - Резултати от тренирането - графика на loss за всяка епоха и на избрани метрики.
  - Baseline сравнение, както и сравнение с модела избран за предишните изисквания.
- Възможност за селекция в демо апликацията между различните модели.
  
### Вариация Б

- Избиране на поне още един готов претрениран модел, който може да бъде използван за целите на задачата.
- Разширяване на оценяващия скрипт с поддръжка на всички модели. Сравнение между тях.
- Създаване на API, което позволява използването на моделите по подадени данни.
- Конфигурация в текстов файл, с която се указва избрания модел, с който да работи API-то (както и параметрите му).

## ВАЖНО

- Поради големината им, **НЕ ДОБАВЯЙТЕ** наборите от данни, както и файловете с чекпойнти на модели в Git и в Мудъл! Dataset-овете и моделите могат ви стоят локално под различни папки, които да бъдат написани в `.gitignore`, за да не бъдат отразени в git. Но не забравяйте да ги махнете от архива за качване в Мудъл, за да няма гигабайтови зипове.
- Не "хардкодвайте" ключове за API-та (и друга поверителна информация като пароли) в кода! Ако имате `.env` файл с ключове за API-та, също го добавете в `.gitignore`! В противен случай някой може да ви открадне достъпа до тези API-та и да използва парите ви за свои цели (понеже за курса изискваме да качите проектите в публични Github репозиторита).

## Препоръчителни технологии

- Работа с набори от данни: `pandas`, `numpy`
- Графики: `matplotlib`, `seaborn`
- Локално зареждане на модел: `transformers`, `pytorch`
- Извикване на модели чрез API: `openai`, `anthropic`, т.н. - специфичната библиотека зависи от доставчика на модела
- Метрики: `scikit-learn` или ръчна имплементация
- Демо апликация: `streamlit`
- API: `FastAPI`, `Flask`
- Конфигурация: `yaml` или `json` (вградена) или `configparser` (вградена, за INI файлове)
- Трениране на модели: `scikit-learn` (за традиционни модели), `pytorch` (за невронни мрежи), `transformers` (за fine-tuning на трансформъри)
- Уеб скрейпинг (ако е необходимо за събиране на данни): `requests`, `BeautifulSoup`, `scrapy`, `aiohttp`
- Обработка на изображения (ако е необходимо): `Pillow`, `OpenCV`
- Обработка на текст (ако е необходимо): `nltk`, `spaCy`, `transformers`
  
## Незадължителни и бонус елементи

- Notebook с анализ на данните (exploratory data analysis - EDA) преди трениране на модел.
- Notebook с визуализации на резултатите от модела/моделите (например confusion matrix, ROC curve, precision-recall curve и др.).
- Оптимизация на хиперпараметрите (hyperparameter tuning) при трениране на модел.
- Крос-валидация (cross-validation) при трениране на модел.
- Използване на GPU за трениране на модели (ако е приложимо).